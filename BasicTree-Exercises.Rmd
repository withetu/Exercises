---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
#------https://www.r-bloggers.com/basic-tree-1-exercises/------
#------http://r-exercises.com/2016/12/15/basic-tree-2/------


#Use read.csv() command to load the lenses.csv data and store it in lens. Use the str() command to see lens.
lens <- read.csv("C:\\Users\\user\\Documents\\GitHub\\Exercises\\lenses.csv")
str(lens)

#Notice there are no column names. The column names are as follows
#index, age, spec_pres, astigmatic, tpr. Use one line code to change the column names to the aforementioned names.
colnames(lens) <- c("index","age","spec_pres","astigmatic","tpr","class")

#Given the meta data
lens$age[lens$age=="1"]="young"
lens$age[lens$age=="2"]="pre-presbyopic"
lens$age[lens$age=="3"]="presbyopic"
lens$spec_pres[lens$spec_pres=="1"]="myope"
lens$spec_pres[lens$spec_pres=="2"]="hypermetrope"

#Use the str() command to see the changes. Also notice that the astigmatic column is a factor that is also storing numbers as characters. To get all of them in the same format, lets convert it to character. Use the code as.character() to convert this column data type to character.
str(lens)
lens$astigmatic=as.character(lens$astigmatic)

#Now change the astigmatic column data to the right names
lens$astigmatic[lens$astigmatic=="1"]="no"
lens$astigmatic[lens$astigmatic=="2"]="yes"

#Use the following code to replace the 1 with “reduced in the tpr column
lens$tpr[lens$tpr==1]="reduced"
lens
#Now type str(lens) to see the dataframe. Notice that the tpr column data type change to character from integer. Anytime you introduce something that is not a number in a number dataframe, it will become a character.

#Go ahead and replace 2 in the tpr column with “normal”
lens$tpr[lens$tpr=="2"]="normal"

#use the table() command to see the counts of each data type
table(lens$astigmatic)

#Notice that there is a g in the count. That could possibly be a typo. We can go ahead and remove that row since there is only one row with that typo. Hint: You can select all rows that does not have that typo and store it back in the lens dataframe.
lens=lens[lens$astigmatic!="g",]

#Great Work. We realized that the index column is not necessary for our modeling purposes. So lets remove the index column.
lens
lens=lens[-1]






#------http://r-exercises.com/2016/12/15/basic-tree-2/------





#load the tree library. If it is not installed then use the install.packages() command to install it.
if(!require(tree)){
  install.packages("tree")
}
library(tree)

#Convert all the feaures(columns) into factors, including the class column
lens$class=as.factor(lens$class)
lens$age=as.factor(lens$age)
lens$spec_pres=as.factor(lens$spec_pres)
lens$astigmatic=as.factor(lens$astigmatic)
lens$tpr=as.factor(lens$tpr)

#Use the sample methods that you learnt from the sample_exercise to split the data into two sets with a SplitRatio of 0.7. Hint: Use caTools library and sample.split() function. Store the results into Train and Test.
library(caTools)
spl=sample.split(lens$class, SplitRatio = 0.7)
Train=lens[spl==TRUE,]
Test=lens[spl==FALSE,]

#Use the tree() command to build the model. Use class as the target variable and everything else as the predictor variable. Also, use the Train variable as the data source. Store the model in a variable called model1
model1=tree(class~., data = Train)

#Use the plot() command to plot the model and use the text() command to add the text.
plot(model1)
text(model1)

#Use the predict() command to predict the classes using the Test dataset. We want to predict the classes. Store this in the variable pred_class
pred_class=predict(model1, newdata = Test, type = "class")

#Use the table() command to print the confusion matrix. Hint: You are comparing the class from the Test set and the predicted vector. This tells you wether the model is answering anything right or wrong
table(Test$class, pred_class)

#use the summary() to print the summary of the model and note the misclassification error rate.
summary(model1)

#Now find the misclassification error rate of the model on the Test data. Use the formula. mean(Test$class != pred_class)
mean(Test$class !=pred_class)

#Compare the two misclassification error rates and determine which is worse and why. How can we improve the model?

  ##The mer is worse on the test set because the model is not good. It is producing more errors when it is seeing new  data. In order to improve the model, we might think of pruning the tree, getting more data or switching to another model.##



```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).
